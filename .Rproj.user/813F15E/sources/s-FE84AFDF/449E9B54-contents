# when I want to clean the global environment
rm(list = ls())


#### data manipulation ####
# start from here
library(dplyr)
library(data.table)

# read the data
setwd("/Volumes/HD-PVRU2/data")
dat <- fread("argentina.csv")

# making base dateframe of event
df1 <- dat %>% filter(is.na(miss)) %>%
  mutate(event = id == lag(id) & fullprice != lag(fullprice)) %>%
  group_by(id) %>%
  select(id, date, fullprice, event, cat1, cat2, cat3, cat4,
         category)
df1$cat1[is.na(df1$cat1)] <- 0
df1$cat2[is.na(df1$cat2)] <- 0
df1$cat3[is.na(df1$cat3)] <- 0
df1$cat4[is.na(df1$cat4)] <- 0
df1$cat5[is.na(df1$cat5)] <- 0
df1$event <- ifelse(df1$event == "TRUE",1,0)
df1$event[is.na(df1$event)] <- 0

# make date as "date" variable
library(lubridate)
df1$date <- dmy(df1$date)

# make "len" on df1
df11 <- df1 %>%
  filter(event == 1) %>%
  #mutate(len = difftime(date,lag(date), units = "days")) %>%
  mutate(direction =
           case_when(lag(fullprice) - fullprice > 0 ~ -1,
                     lag(fullprice) - fullprice < 0 ~ 1))
df11$len[is.na(df11$len)] <- 0

# make another dataset combining df11$len into df1
df1 <- left_join(df1,df11)
df1$len[is.na(df1$len)] <- 0
df1$len <- as.numeric(df1$len)
df1$direction[is.na(df1$direction)] <- 0

# remove unnecessary data
rm(dat,df11)

# mutate date1 to refer time duration and fill NA as last non-NA
# it works perfectly but very slow ca. 20 mins
library(tidyr)
df1 <- df1 %>% mutate(date1 =
                        case_when(lag(event == 1) ~ lag(date))) %>%
  arrange(id,date) %>% group_by(id) %>% fill(date1)

# create a duration
df1 <- df1 %>%
  mutate(duration = difftime(date, date1, units = "days"))
df1$duration <- as.integer(df1$duration)
df1 <- df1 %>% na.omit()

# make sure that all prices are positive
df1 <- df1 %>% filter(fullprice > 0)

# making a weekday
df1$day <- weekdays(df1$date)
df1$dayfac <- factor(df1$day,
                     levels = c("Monday","Tuesday","Wednesday",
                                "Thursday","Friday","Saturday",
                                "Sunday"))

# make price category(low, medium, high)
df1 <- df1 %>%
  mutate(pricecat =
           case_when(logprice < 1.6467 ~ "Q1",
                     logprice >= 1.6467 & logprice < 2.2396 ~ "Q2",
                     logprice >= 2.2396 & logprice < 2.9907 ~ "Q3",
                     logprice >= 2.9907 ~ "Q4"))
df1$pricecat <- factor(df1$pricecat,
                       levels = c("Q1","Q2","Q3","Q4"))


# see day of the week comparison
# arg <- df1 %>% group_by(dayfac) %>%
#   summarize(mean_eve = mean(event), SD_eve = sd(event),
#             mean_dir = mean(direction), SD_dir = sd(direction))
#
# cat1 <- df1 %>% group_by(cat1) %>%
#   summarize(mean_eve = mean(event), SD_eve = sd(event),
#             mean_dir = mean(direction), SD_dir = sd(direction))
#
# cat2 <- df1 %>% group_by(cat2) %>%
#   summarize(mean_eve = mean(event), SD_eve = sd(event),
#             mean_dir = mean(direction), SD_dir = sd(direction))
#
# cat3 <- df1 %>% group_by(cat1) %>%
#   summarize(mean_eve = mean(event), SD_eve = sd(event),
#             mean_dir = mean(direction), SD_dir = sd(direction))
#
# cat4 <- df1 %>% group_by(cat2) %>%
#   summarize(mean_eve = mean(event), SD_eve = sd(event),
#             mean_dir = mean(direction), SD_dir = sd(direction))

#### visualization for thesis ####
library(ggplot2)
# fullprice histogram
ggplot(data = df1, aes(x = fullprice)) +
  geom_histogram(bins = 50) + xlim(0,200) +
  labs(x = 'price', y = 'count')+
  theme(axis.text=element_text(size=17),
        axis.title=element_text(size=17,face="bold"))

# magnitude histogram
ggplot(data = df1, aes(x = magnitude)) +
  geom_histogram(bins = 1000) + xlim(-25,25) + ylim(0,8000) +
  labs(x = 'magnitude of price change', y = 'count')+
  theme(axis.text=element_text(size=17),
        axis.title=element_text(size=17,face="bold"))

# histgram cat 991
df1 %>% filter(category=="271")%>%
  ggplot(aes(x = fullprice)) +
  geom_histogram(bins = 50)  +ylim(0,8000) +
  labs(x = 'price', y = 'count')+
  theme(axis.text=element_text(size=17),
        axis.title=element_text(size=17,face="bold"))

# probability dist. on day
df1 %>% group_by(dayfac) %>%
  summarise(mean_event = mean(event)) %>%
  ggplot(aes(x=dayfac, y=mean_event)) +
  geom_bar(stat = "identity") +
  labs(x = 'day of a week', y = 'Probability')+
  geom_abline(intercept = 0.0244, slope = 0,color="red")+
  theme(axis.text=element_text(size=17),
        axis.title=element_text(size=17,face="bold"),
        axis.title.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.ticks.y=element_blank())+
  scale_x_discrete(labels=c("Mon","Tue","Wed","Thu","Fri","Sat",
                            "Sun"))

# probability dist. on week
df1 %>% group_by(weekofm) %>%
  summarise(mean_event = mean(event)) %>%
  ggplot(aes(x=weekofm, y=mean_event)) +
  geom_bar(stat = "identity") +
  labs(x = 'week of a month', y = 'Probability')+
  geom_abline(intercept = 0.0244, slope = 0,color="red")+
  theme(axis.text=element_text(size=15),
        axis.title=element_text(size=15,face="bold"),
        axis.title.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.ticks.y=element_blank())+
  scale_x_discrete(labels=c("1st","2nd","3rd","4th","5th"))

# probability dist. on month
df1 %>% group_by(month) %>%
  summarise(mean_event = mean(event)) %>%
  ggplot(aes(x=month, y=mean_event)) +
  geom_bar(stat = "identity") +
  labs(x = 'month of a year', y = 'Probability')+
  geom_abline(intercept = 0.0244, slope = 0,color="red")+
  theme(axis.text=element_text(size=13),
        axis.title=element_text(size=15,face="bold"),
        axis.title.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.ticks.y=element_blank())+
  scale_x_discrete(labels=c("Jan","Feb","Mar","Apr","May","Jun","Jul",
                            "Aug","Sep","Oct","Nov","Dec"))


# probability dist. on season
df1 %>% group_by(season) %>%
  summarise(mean_event = mean(event)) %>%
  ggplot(aes(x=season, y=mean_event)) +
  geom_bar(stat = "identity") +
  labs(x = 'season', y = 'Probability')+
  geom_abline(intercept = 0.0244, slope = 0,color="red")+
  theme(axis.text=element_text(size=15),
        axis.title=element_text(size=15,face="bold"),
        axis.title.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.ticks.y=element_blank())+
  scale_x_discrete(labels=c("Winter","Spring","Summer","Fall"))

# probability dist. on pricecat
df1 %>% group_by(pricecat) %>%
  summarise(mean_event = mean(event)) %>%
  ggplot(aes(x=pricecat, y=mean_event)) +
  geom_bar(stat = "identity") +
  labs(x = 'price category', y = 'probability of price change')+
  geom_abline(intercept = 0.0244, slope = 0,color="red")

# probability dist. on category
df1 %>% group_by(category) %>%
  summarise(mean_event = mean(event)) %>%
  ggplot(aes(x=category, y=mean_event)) +
  geom_bar(stat = "identity") + xlim(0,300) +
  labs(x = 'price category', y = 'probability of price change')+
  geom_abline(intercept = 0.0244, slope = 0,color="red")

#### visualization####
library(ggplot2)
ggplot(arg, aes(dayfac,mean_eve)) + geom_bar(stat = "identity") +
  labs(x = "day", y = "probability")

# take subset for each cat, and see the pattern of event prob.
cat1 <- df1 %>% filter(cat1 != 0)
cat2 <- df1 %>% filter(cat2 != 0)
cat3 <- df1 %>% filter(cat3 != 0)
cat4 <- df1 %>% filter(cat4 != 0)

cat1day <- cat1 %>% group_by(dayfac) %>%
  summarize(mean_eve = mean(event), SD_eve = sd(event),
            mean_dir = mean(direction), SD_dir = sd(direction))

cat2day <- cat2 %>% group_by(dayfac) %>%
  summarize(mean_eve = mean(event), SD_eve = sd(event),
            mean_dir = mean(direction), SD_dir = sd(direction))

cat3day <- cat3 %>% group_by(dayfac) %>%
  summarize(mean_eve = mean(event), SD_eve = sd(event),
            mean_dir = mean(direction), SD_dir = sd(direction))

cat4day <- cat4 %>% group_by(dayfac) %>%
  summarize(mean_eve = mean(event), SD_eve = sd(event),
            mean_dir = mean(direction), SD_dir = sd(direction))

library(ggplot2)
ggplot(cat1day, aes(dayfac,mean_eve)) + geom_bar(stat = "identity") +
  labs(x = "day", y = "probability")

ggplot(cat2day, aes(dayfac,mean_eve)) + geom_bar(stat = "identity") +
  labs(x = "day", y = "probability")

ggplot(cat3day, aes(dayfac,mean_eve)) + geom_bar(stat = "identity") +
  labs(x = "day", y = "probability")

ggplot(cat4day, aes(dayfac,mean_eve)) + geom_bar(stat = "identity") +
  labs(x = "day", y = "probability")

# skewness
library(e1071)
skewness(df1$fullprice)
df1 <- df1 %>% mutate(logprice =
                        if_else(fullprice > 0, log10(fullprice) + 1,
                                0))

# # make week day dummy
# df1 <- df1 %>% mutate(Mon = case_when(day == 'Monday' ~ 1,
#                                       day != 'Monday' ~ 0))
#
# df1 <- df1 %>% mutate(Tue = case_when(day == 'Tuesday' ~ 1,
#                                       day != 'Tuesday' ~ 0))
#
# df1 <- df1 %>% mutate(Wed = case_when(day == 'Wednesday' ~ 1,
#                                       day != 'Wednesday' ~ 0))
#
# df1 <- df1 %>% mutate(Thu = case_when(day == 'Thursday' ~ 1,
#                                       day != 'Thursday' ~ 0))
#
# df1 <- df1 %>% mutate(Fri = case_when(day == 'Friday' ~ 1,
#                                       day != 'Friday' ~ 0))
#
# df1 <- df1 %>% mutate(Sat = case_when(day == 'Saturday' ~ 1,
#                                       day != 'Saturday' ~ 0))
#
# df1 <- df1 %>% mutate(Sun = case_when(day == 'Sunday' ~ 1,
#                                       day != 'Sunday' ~ 0))


#### logisic regression daily####
model1 <- glm(event ~ duration + day,
              family = binomial(link = "logit"), data = df1)
summary(model1)

library(biglm)
model <- bigglm(event ~ duration + day, data = df1,
                 family = binomial(link = "logit"), maxit = 50)
summary(model)

df1 <- df1 %>% mutate(weekofm = factor(weekofm)) %>%
  mutate(category = factor(category)) %>%
  mutate(season = factor(season))

library(speedglm)
model <- glm(event ~ duration + day +weekofm +  month +
                    fullprice+ pricecat+ category,
                  data = df1,
                  family = binomial(link = "logit"), maxit = 50)
summary(model)

anova(model, test = 'Chisq')

library(BaylorEdPsych)
PseudoR2(model)

# duration model analysis
library(survival)
library(ggplot2)

# Kaplan Meier Survival Curve
km <- with(df1, Surv(len, event) ~ 1)
summary(km)

km_fit <- survfit(Surv(len, event) ~ 1, data=df1)
summary(km_fit)

plot(km_fit, xlab="Days", main = 'Kaplan Meyer Plot')

# hazard rate h(t) = f(t) / S(t)  or  f(t) / (1 - F(t))
# discrete hazard rate
library(muhaz)
fit1 <- kphaz.fit(df1$len, df1$event)
kphaz.plot(fit1)

library(bshazard)
fit<-bshazard(Surv(len, event) ~ 1,data=df1)
print.bshazard(fit)
plot(fit,xlim=c(0,400))

# Fit Cox Model
cox <- coxph(Surv(len, event) ~ day, data = df1)
summary(cox)

cox_fit <- survfit(cox)
plot(cox_fit, main = "cph model", xlab="Days")



# Basic stats: How many price changes are there
# (what's the unconditional probability)
# Look at probability of price change for every weekday
# Look at hazard rate (would be good to get confidence intervals)
# maybe xlim = 360?
# Re-do logistic regression
# Start writing (descriptive stats part)

#### weekly analysis ####
# make weekly data
library(dplyr)
library(zoo)
library(lubridate)
df1 <- df1 %>% mutate(week = week(date))
weekly <- df1 %>% group_by(id,week) %>%
  summarise_each(funs(mean)) %>% select(-cat1,-cat2,-len)

weekly$day <- weekdays(weekly$date)
weekly$dayfac <- factor(weekly$day,
                        levels = c("Monday","Tuesday","Wednesday",
                                   "Thursday","Friday","Saturday",
                                   "Sunday"))

# make event, direction, and logprice
weekly <- weekly %>% group_by(id) %>%
  mutate(event = case_when (lag(fullprice) == fullprice ~ 0,
                            lag(fullprice) != fullprice ~ 1)) %>%
  mutate(direction =
           case_when(lag(fullprice) - fullprice > 0 ~ -1,
                     lag(fullprice) - fullprice < 0 ~ 1,
                     lag(fullprice) - fullprice == 0 ~ 0)) %>%
  mutate(logprice = log(fullprice+1))
weekly$event[is.na(weekly$event)] <- 0
weekly$direction[is.na(weekly$direction)] <- 0

weekly$eventfac <- factor(weekly$event)
weekly$direcfac <- factor(weekly$direction)

weekly <- weekly %>% select(-bievent,-classdirec)

weekly$month <- factor(format(weekly$date, "%B"),
                       levels = c("January","February","March",
                                  "April","May","June","July",
                                  "August","September","October",
                                  "November","December"))

weekly <- weekly %>% select(-cat3,-cat4)

weekly <- weekly %>%
  mutate(pricecat = case_when(logprice > 3.087 ~ "Q4",
                              logprice <= 3.087 & logprice > 2.299 ~
                                "Q3",
                              logprice <= 2.299 & logprice > 1.685 ~
                                "Q2",
                              logprice < 1.685 ~ "Q1"))
weekly$pricecat <- factor(weekly$pricecat,
                          levels = c("Q1","Q2","Q3","Q4"))

#### visualization weekly####
library(ggplot2)
# histgram (logprice)
ggplot(data = weekly, aes(x = logprice)) +
  geom_histogram(fill = 'orangered2') +
  labs(title = 'Histogram of log item price + 1')

# distribution difference between event
weekly %>%
  ggplot(aes(x = logprice, fill = factor(bievent))) +
  geom_density(adjust = 2, alpha = 0.6) +
  labs(x = 'Log price', y = '')

weekly %>%
  ggplot(aes(x = pricecat, fill = factor(bievent))) +
  geom_density(adjust = 2, alpha = 0.6) +
  labs(x = 'Log price', y = '')

weekly %>% group_by(duration) %>%
  summarise(mean_event = mean(event)) %>%
  ggplot(aes(x=duration, y=mean_event)) +
  geom_point(size=0.5) +
  geom_smooth(method = "loess", color = "red", size=0.5)

# some price have mean of 1
weekly %>% group_by(logprice) %>%
  summarise(mean_event = mean(event)) %>%
  ggplot(aes(x=logprice, y=mean_event)) +
  geom_point(size=0.5) +
  geom_smooth(method = "loess", color = "red", size=0.5)

weekly %>% group_by(pricecat) %>%
  summarise(mean_event = mean(event)) %>%
  ggplot(aes(x=pricecat, y=mean_event)) +
  geom_bar(stat = "identity")

weekly %>% group_by(month) %>%
  summarise(mean_event = mean(event)) %>%
  ggplot(aes(x=reorder(month,mean_event), y=mean_event)) +
  geom_bar(stat = "identity") + coord_flip()

weekly %>% ggplot(aes(pricecat,bievent)) +
  geom_bar(stat = "identity")

ggplot(weekly, aes(pricecat, fill = factor(bievent))) +
  geom_bar(stat = "count")

ggplot(df1, aes(month, fill = factor(bievent))) +
  geom_bar(stat = "count")

ggplot(df1, aes(season, fill = factor(bievent))) +
  geom_bar(stat = "count")

ggplot(df1, aes(duration, fill = factor(bievent))) +
  geom_bar(stat = "count") + coord_cartesian(xlim = c(0, 200))

# for data description
table(weekly$bievent)
prop.table(table(weekly$bievent))
ggplot(data = weekly, aes(bievent)) + geom_bar()

table(df1$direction)
prop.table(table(weekly$classdirec))
ggplot(data = df1, aes(classdirec)) + geom_bar()

#### logisic regression weekly ####
model1 <- glm(event ~ duration + fullprice+factor(weekofm)+month+
                factor(category),
              family = binomial(link = "logit"), data = weekly)
summary(model1)

library(aod)
wald.test(b = coef(model1), Sigma = vcov(model1),Terms=91)

model1 <- glm(event ~ duration + fullprice+week2+week4+Feb+Mar+May+
                Sep+Oct+Dec+cat271+cat991,
              family = binomial(link = "logit"), data = weekly)
summary(model1)
library(aod)
wald.test(b = coef(model1), Sigma = vcov(model1),Terms=13)


exp(coef(firthe))

df1 %>% filter(category=="991") %>%
  summarise(mean)

#### prediction model weekly####
# logistic
# create training and validation data from given data
library(caTools)
set.seed(88)
split <- sample.split(weekly, SplitRatio = 0.70)

#get training and test data
train <- subset(weekly, split == TRUE)
test <- subset(weekly, split == FALSE)

#logistic regression model
trainmodel <- glm(bievent ~ duration + day, data = train,
                  family = binomial(link = "logit"), maxit = 50)
summary(trainmodel)

# ANOVA #### ANOVA does not work for bigglm
anova(trainmodel, test = 'Chisq')

predict <- predict(trainmodel, newdata = test, type = "response")

#confusion matrix
table(test$bievent, predict > 0.5)

#ROCR Curve
library(ROCR)
ROCRpred <- prediction(predict, test$bievent)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf) # AUC score = 0.6849195

library(Metrics)
auc(test$bievent, predict)

#### ML techniques weekly####
# Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"

library(doParallel)
registerDoParallel(core = 4)

library(caret)
# a) linear algorithms
set.seed(7)
fit.lda <- train(eventfac ~ duration + day, data = train,
                 method="lda", metric = metric, trControl=control)
print(fit.lda)

set.seed(7)
lda <- train(factor(logprice) ~ duration + day + month + pricecat +
               direction,
             data = train,method="lda", trControl=control)
print(lda)

# b) nonlinear algorithms
# CART
set.seed(7)
cart <- train(eventfac ~ duration + day, data = train,
              method="rpart",
              metric = metric, trControl = control)
print(cart)

# SMOTE method
train$eventfac <- make.names(train$eventfac)
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
ctrl$sampling <- "smote"
set.seed(7)
smotecart <- train(eventfac ~ duration + day + pricecat + month,
                   data = train, method="rpart", verbose = FALSE,
                   metric = "ROC", trControl = ctrl)

pred <- predict(smotecart, test)
confusionMatrix(pred, test$eventfac)

# weighted sampling
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
model_weights <- ifelse(train$eventfac == "1",
                        (1/table(train$eventfac)[1]) * 0.5,
                        (1/table(train$eventfac)[2]) * 0.5)
weighted_cart <- train(eventfac ~ duration + day + pricecat + month,
                       data = train, method = "rpart",
                       verbose = FALSE, weights = model_weights,
                       metric = "ROC", trControl = ctrl)

set.seed(7)
fit.cart <- train(eventfac ~ duration + day, data = train,
                  method="rpart",
                  metric = metric, trControl = control)
# kNN
set.seed(7)
fit.knn <- train(eventfac ~ duration + day + cat1 + month + pricecat,
                 data = train, method="knn",
                 metric = metric, trControl = control)
# c) advanced algorithms
# SVM
set.seed(7)
fit.svm <- train(eventfac ~ duration + day, data = train,
                 method ="svmRadial", metric=metric,
                 trControl=control)
# Random Forest # too big
set.seed(7)
fit.rf <- train(eventfac ~ duration + day, data = train, method="rf",
                metric=metric, trControl=control)

set.seed(7)
direc.rf <- train(direcfac ~ duration + day, data = train,
                  method="rf",
                  metric=metric, trControl=control)

# Decision tree
library(caret)
library(C50)
dt <- C5.0(direcfac ~ duration + day + month + pricecat + cat1,
           data = train, trials = 10, rules = TRUE)
# insufficient memory
dt <- C5.0(factor(logprice) ~ duration + day + month + pricecat +
             direction,
           data = train, trials = 10, rules = TRUE)
summary(dt)
pred <- predict(dt, newdata = test)
confusionMatrix(pred,test$direcfac)

# estimate skill of LDA on the validation dataset
pred <- predict(fit.lda, test)
confusionMatrix(pred, test$eventfac)

pred <- predict(cart, test)
confmat <- confusionMatrix(pred, test$eventfac)

# Random forest
library(randomForest)
set.seed(7)
rf <- randomForest(event ~ duration + day, data = train,
                   importance = TRUE, proximity = TRUE)
print(rf)

# Naive Bayes
library(e1071)
nb <- naiveBayes(event ~ duration + day + month + pricecat,
                 data = train, laplace = 1)

nb <- naiveBayes(direcfac ~ duration + day + month + pricecat + cat1,
                 data = train)

print(nb)

predict <- predict(nb, newdata = test, type = "class")
conf_matrix <- table(predict, test$direcfac)
confmat <- confusionMatrix(predict, test$direcfac)

library(gmodels)
CrossTable(predict, test$eventfac,
           prop.chisq = FALSE, prop.t = FALSE,
           dnn = c('predicted', 'actual'))

# LASSO
library(penalized)
pen <- penalized(Surv(duration, event),
                 penalized = event ~ day + duration + month +
                   pricecat + cat1,
                 data = df1, lambda1 = 10)
show(pen)
coefficients(pen)
coefficients(pen, "penalized")
basehaz(pen)

#### monthly analysis ####
# make monthly data
library(dplyr)
library(zoo)
library(lubridate)
df1 <- df1 %>% mutate(monthly = month(date))
monthly <- df1 %>% group_by(id,monthly) %>%
  summarise_each(funs(mean)) %>% select(-cat1,-cat2,-len)

monthly$day <- weekdays(monthly$date)
monthly$dayfac <- factor(monthly$day,
                         levels = c("Monday","Tuesday","Wednesday",
                                    "Thursday","Friday","Saturday",
                                    "Sunday"))

# make event and direction
monthly <- monthly %>% group_by(id) %>%
  mutate(event = case_when (lag(fullprice) == fullprice ~ 0,
                            lag(fullprice) != fullprice ~ 1)) %>%
  mutate(direction =
           case_when(lag(fullprice) - fullprice > 0 ~ -1,
                     lag(fullprice) - fullprice < 0 ~ 1,
                     lag(fullprice) - fullprice == 0 ~ 0))
monthly$event[is.na(monthly$event)] <- 0
monthly$direction[is.na(monthly$direction)] <- 0

monthly$eventfac <- factor(monthly$event)
monthly$direcfac <- factor(monthly$direction)

monthly <- monthly %>% select(-bievent, -classdirec)

monthly$month <- factor(format(monthly$date, "%B"),
                        levels = c("January","February","March",
                                   "April","May","June","July",
                                   "August","September","October",
                                   "November","December"))

library(zoo)
monthly$yq <- as.yearqtr(as.yearmon(monthly$date) + 1/12)
monthly$season <- factor(format(monthly$yq, "%q"), levels = 1:4,
                         labels = c("winter", "spring",
                                    "summer", "fall"))
monthly <- monthly %>% select(-yq)

monthly <- monthly %>%
  mutate(pricecat = case_when(logprice > 3.1281 ~ "Q4",
                              logprice <= 3.1281 & logprice > 2.3234
                              ~"Q3",
                              logprice <= 2.3234 & logprice > 1.7029
                              ~"Q2",
                              logprice < 1.7029 ~ "Q1"))
monthly$pricecat <- factor(monthly$pricecat,
                           levels = c("Q1","Q2","Q3","Q4"))

#### visualization monthly####
library(ggplot2)
# histgram (logprice)
ggplot(data = monthly, aes(x = logprice)) +
  geom_histogram(fill = 'orangered2') +
  labs(title = 'Histogram of log item price + 1')

# distribution difference between event
monthly %>%
  ggplot(aes(x = logprice, fill = factor(bievent))) +
  geom_density(adjust = 2, alpha = 0.6) +
  labs(x = 'Log price', y = '')

monthly %>%
  ggplot(aes(x = pricecat, fill = factor(bievent))) +
  geom_density(adjust = 2, alpha = 0.6) +
  labs(x = 'Log price', y = '')

monthly %>% group_by(duration) %>%
  summarise(mean_event = mean(event)) %>%
  ggplot(aes(x=duration, y=mean_event)) +
  geom_point(size=0.5) +
  geom_smooth(method = "loess", color = "red", size=0.5)

# some price have mean of 1
monthly %>% group_by(logprice) %>%
  summarise(mean_event = mean(event)) %>%
  ggplot(aes(x=logprice, y=mean_event)) +
  geom_point(size=0.5) +
  geom_smooth(method = "loess", color = "red", size=0.5)

monthly %>% group_by(pricecat) %>%
  summarise(mean_event = mean(event)) %>%
  ggplot(aes(x=pricecat, y=mean_event)) +
  geom_bar(stat = "identity")

monthly %>% group_by(month) %>%
  summarise(mean_event = mean(event)) %>%
  ggplot(aes(x=reorder(month,mean_event), y=mean_event)) +
  geom_bar(stat = "identity") + coord_flip()

monthly %>% ggplot(aes(pricecat,bievent)) +
  geom_bar(stat = "identity")

ggplot(monthly, aes(pricecat, fill = factor(bievent))) +
  geom_bar(stat = "count")

ggplot(df1, aes(month, fill = factor(bievent))) +
  geom_bar(stat = "count")

ggplot(df1, aes(season, fill = factor(bievent))) +
  geom_bar(stat = "count")

ggplot(df1, aes(duration, fill = factor(bievent))) +
  geom_bar(stat = "count") + coord_cartesian(xlim = c(0, 200))

# for data description
table(monthly$bievent)
prop.table(table(monthly$bievent))
ggplot(data = monthly, aes(bievent)) + geom_bar()

table(df1$direction)
prop.table(table(monthly$classdirec))
ggplot(data = df1, aes(classdirec)) + geom_bar()

#### logisic regression monthly ####
model1 <- glm(event ~ duration + day,
              family = binomial(link = "logit"), data = monthly)
summary(model1)

#### prediction model monthly####
# logistic
# create training and validation data from given data
library(caTools)
set.seed(88)
split <- sample.split(monthly, SplitRatio = 0.70)

#get training and test data
train <- subset(monthly, split == TRUE)
test <- subset(monthly, split == FALSE)

#logistic regression model
trainmodel <- glm(event ~ duration + day, data = train,
                  family = binomial(link = "logit"), maxit = 50)
summary(trainmodel)

# ANOVA #### ANOVA does not work for bigglm
anova(trainmodel, test = 'Chisq')

predict <- predict(trainmodel, newdata = test, type = "response")

#confusion matrix
table(test$event, predict > 0.5)

library(Metrics)
auc(test$event, predict)
# 0.6405101

#ROCR Curve
library(ROCR)
ROCRpred <- prediction(predict, test$bievent)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf) # AUC score = 0.7287791

#### ML techniques monthly####
# Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"

library(doParallel)
registerDoParallel(core = 4)

library(caret)
# a) linear algorithms
set.seed(7)
lda <- train(eventfac ~ duration + day, data = train,
                 method="lda", metric = metric, trControl=control)
print(lda)
pred <- predict(lda, test)
confusionMatrix(pred, test$eventfac)
auc(test$event, pred)
# acc 0.7423, no inf. 0.7369, kappa 0.0968, auc 0.5356091

set.seed(7)
lda <- train(factor(logprice) ~ duration + day + month + pricecat +
               direction,
             data = train,method="lda", trControl=control)
print(lda)

# b) nonlinear algorithms
# CART
set.seed(7)
cart <- train(eventfac ~ duration + day, data = train,
              method="rpart",
              metric = metric, trControl = control)
print(cart)
pred <- predict(cart, test)
confusionMatrix(pred, test$eventfac)
auc(test$event, pred)
# acc 0.7431, no inf. 0.7369, kappa 0.1252, auc 0.5473993

# SMOTE method
train$eventfac <- make.names(train$eventfac)
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
ctrl$sampling <- "smote"
set.seed(7)
smotecart <- train(eventfac ~ duration + day + pricecat + month,
                   data = train, method="rpart", verbose = FALSE,
                   metric = "ROC", trControl = ctrl)

pred <- predict(smotecart, test)
confusionMatrix(pred, test$eventfac)

# weighted sampling
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
model_weights <- ifelse(train$eventfac == "1",
                        (1/table(train$eventfac)[1]) * 0.5,
                        (1/table(train$eventfac)[2]) * 0.5)
weighted_cart <- train(eventfac ~ duration + day + pricecat + month,
                       data = train, method = "rpart",
                       verbose = FALSE, weights = model_weights,
                       metric = "ROC", trControl = ctrl)

set.seed(7)
fit.cart <- train(eventfac ~ duration + day, data = train,
                  method="rpart",
                  metric = metric, trControl = control)
# kNN
set.seed(7)
knn <- train(eventfac ~ duration + day,
                 data = train, method="knn",
                 metric = metric, trControl = control)
print(fit.knn)
pred <- predict(fit.knn, test)
confusionMatrix(pred, test$eventfac)
auc(test$event, pred)
# acc 0.7908, no inf. 0.7369, kappa 0.4447, auc 0.7160267

# c) advanced algorithms
# SVM
set.seed(7)
svm <- train(eventfac ~ duration + day, data = train,
             method ="svmRadial", metric=metric,
             trControl=control)

# Random Forest # too big
set.seed(7)
rf <- train(eventfac ~ duration + day, data = train, method="rf",
            metric=metric, trControl=control)
print(rf)
pred <- predict(fit.knn, test)
confusionMatrix(pred, test$eventfac)
auc(test$event, pred)
# NOT YET
# acc 0.7908, no inf. 0.7369, kappa 0.4447, auc 0.7160267

set.seed(7)
direc.rf <- train(direcfac ~ duration + day, data = train,
                  method="rf",
                  metric=metric, trControl=control)

# Decision tree
library(caret)
library(C50)
dt <- C5.0(eventfac ~ duration + day,
           data = train, trials = 10, rules = TRUE)
summary(dt)
pred <- predict(dt, newdata = test)
confusionMatrix(pred,test$eventfac)
auc(test$event, pred)
# acc 0.7736, no inf. 0.7369, kappa 0.2558, auc 0.6003305

# insufficient memory
dt <- C5.0(factor(logprice) ~ duration + day + month + pricecat +
             direction,
           data = train, trials = 10, rules = TRUE)

# Random forest
library(randomForest)
set.seed(7)
rf <- randomForest(event ~ duration + day, data = train,
                   importance = TRUE, proximity = TRUE)
print(rf)

# Naive Bayes
library(e1071)
nb <- naiveBayes(eventfac ~ duration + day,
                 data = train, laplace = 1)
predict <- predict(nb, newdata = test, type = "class")
table(predict, test$eventfac)
confusionMatrix(predict, test$eventfac)
auc(test$event, pred)
# acc 0.7366, no inf. 0.7369, kappa 0.1282, auc 0.6003305

nb <- naiveBayes(direcfac ~ duration + day + month + pricecat ,
                 data = train)

print(nb)

library(gmodels)
CrossTable(predict, test$eventfac,
           prop.chisq = FALSE, prop.t = FALSE,
           dnn = c('predicted', 'actual'))

# LASSO
library(penalized)
pen <- penalized(Surv(duration, event),
                 penalized = event ~ day + duration + month +
                   pricecat,
                 data = train, lambda1 = 10)
show(pen)
coefficients(pen)
coefficients(pen, "penalized")
basehaz(pen)

#### change of magnitude ####
# create magnitude
library(dplyr)
monthly <- monthly %>% group_by(id) %>%
  mutate(magnitude = lag(fullprice) - fullprice)
monthly$magnitude[is.na(monthly$magnitude)] <- 0

weekly <- weekly %>% group_by(id) %>%
  mutate(magnitude = lag(fullprice) - fullprice)
weekly$magnitude[is.na(weekly$magnitude)] <- 0

df1 <- df1 %>% group_by(id) %>%
  mutate(magnitude = lag(fullprice) - fullprice)
df1$magnitude[is.na(df1$magnitude)] <- 0

# create logmagnitude
monthly <- monthly %>% group_by(id) %>%
  mutate(logmag = lag(logprice) - logprice)
monthly$logmag[is.na(monthly$logmag)] <- 0

weekly <- weekly %>% group_by(id) %>%
  mutate(logmag = lag(logprice) - logprice)
weekly$logmag[is.na(weekly$logmag)] <- 0

df1 <- df1 %>% group_by(id) %>%
  mutate(logmag = lag(logprice) - logprice)
df1$logmag[is.na(df1$logmag)] <- 0

# create absolute logmag
monthly <- monthly %>%
  mutate(abslog = abs(logmag))

weekly <- weekly %>%
  mutate(abslog = abs(logmag))

# visualization
library(ggplot2)
# histgram
ggplot(data = monthly, aes(x = magnitude)) + xlim(-1000,1000) +
  geom_histogram(fill = 'orangered2',bins = 1000) + ylim(0,1000)

ggplot(data = monthly, aes(x = absmag)) + xlim(0,500) +
  geom_histogram(fill = 'orangered2',bins = 1000) + ylim(0,250)

ggplot(data = weekly, aes(x = magnitude)) + xlim(-1000,1000) +
  geom_histogram(fill = 'orangered2',bins = 1000) + ylim(0,2000)

ggplot(data = df1, aes(x = magnitude)) + xlim(-3000,3000) +
  ylim(0,2000) + geom_histogram(fill = 'orangered2',bins = 1000)

ggplot(data = monthly, aes(x = logmag)) + xlim(-2,2)+
  geom_histogram(fill = 'orangered2',bins = 1000) + ylim(0,50)

ggplot(data = df1, aes(x = logmag)) + xlim(-2.5,2.5) +
  geom_histogram(fill = 'orangered2',bins = 1000) + ylim(0,200)

# create categories
monthly <- monthly %>%
  mutate(magcat = case_when(magnitude == 0 ~ "0",
                            magnitude > 0 & magnitude < 0.101 ~
                              "posMod",
                            magnitude >= 0.101 ~ "posBig",
                            magnitude < 0 & magnitude > -0.133 ~
                              "negMod",
                            magnitude <= -0.133 ~ "negBig"))
monthly$magcat <- factor(monthly$magcat,
                         levels = c("negBig","negMod","0",
                                    "posMod","posBig"))

monthly <- monthly %>%
  mutate(absmag = abs(magnitude)) %>%
  mutate(abscat = case_when(absmag == 0 ~ "0",
                            absmag > 0 & absmag <= 0.117 ~ "small",
                            absmag > 0.117 & absmag <= 0.511 ~
                              "moderate",
                            absmag > 0.511 & absmag <= 2.871 ~ "big",
                            absmag > 2.871 ~ "huge"))
monthly$abscat <- factor(monthly$abscat,
                         levels = c("0","small","moderate",
                                    "big","huge"))

monthly <- monthly %>%
  mutate(logcat = case_when(logmag == 0 ~ "0",
                            logmag > 0 & magnitude < 0.012802 ~
                              "posMod",
                            magnitude >= 0.012802 ~ "posBig",
                            magnitude < 0 & magnitude > -0.013814 ~
                              "negMod",
                            magnitude <= -0.013814 ~ "negBig"))
monthly$logcat <- factor(monthly$logcat,
                         levels = c("negBig","negMod","0",
                                    "posMod","posBig"))

weekly <- weekly %>%
  mutate(magcat = case_when(magnitude == 0 ~ "0",
                            magnitude > 0 & magnitude < 8 ~
                              "posMod",
                            magnitude >= 8 ~ "posBig",
                            magnitude < 0 & magnitude > -10 ~
                              "negMod",
                            magnitude <= -10 ~ "negBig"))
weekly$magcat <- factor(weekly$magcat,
                        levels = c("negBig","negMod","0",
                                   "posMod","posBig"))

weekly <- weekly %>%
  mutate(absmag = abs(magnitude)) %>%
  mutate(abscat = case_when(absmag == 0 ~ "0",
                            absmag > 0 & absmag <= 9 ~ "small",
                            absmag > 9 & absmag <= 110 ~ "moderate",
                            absmag > 110 & absmag <= 240 ~ "big",
                            absmag > 240 ~ "huge"))
weekly$abscat <- factor(weekly$abscat,
                        levels = c("0","small","moderate",
                                   "big","huge"))

df1 <- df1 %>%
  mutate(magcat = case_when(magnitude == 0 ~ "0",
                            magnitude > 0 & magnitude < 61 ~
                              "posMod",
                            magnitude >= 61 ~ "posBig",
                            magnitude < 0 & magnitude > -67 ~
                              "negMod",
                            magnitude <= -67 ~ "negBig"))
df1$magcat <- factor(df1$magcat,
                     levels = c("negBig","negMod","0",
                                "posMod","posBig"))

df1 <- df1 %>%
  mutate(absmag = abs(magnitude)) %>%
  mutate(abscat = case_when(absmag == 0 ~ "0",
                            absmag > 0 & absmag <= 1 ~ "small",
                            absmag > 1 & absmag <= 64 ~ "moderate",
                            absmag > 64 & absmag <= 269 ~ "big",
                            absmag > 269 ~ "huge"))
df1$abscat <- factor(df1$abscat,
                     levels = c("0","small","moderate",
                                "big","huge"))

df1 <- df1 %>%
  mutate(logcat = case_when(logmag == 0 ~ "0",
                            logmag > 0 & logmag < 0.7 ~
                              "posMod",
                            logmag >= 0.7 ~ "posBig",
                            logmag < 0 & logmag > -0.7 ~
                              "negMod",
                            logmag <= -0.7 ~ "negBig"))
df1$logcat <- factor(df1$logcat,
                     levels = c("negBig","negMod","0",
                                "posMod","posBig"))

library(doParallel)
registerDoParallel(core = 5)
# decision tree for absolute magcat for monthly data
library(caret)
library(C50)
set.seed(7)
dt <- C5.0(abscat ~ duration + day + logprice +
             pricecat + season + month,
           data = train, trials = 10, rules = TRUE)
summary(dt)
pred <- predict(dt, newdata = test)
confusionMatrix(pred,test$abscat)
# acc 0.5491, no inf. 0.2639, kappa 0.4185

# decision tree for magcat for monthly data
library(C50)
set.seed(7)
dt <- C5.0(magcat ~ duration + day + logprice +
             pricecat + season + month,
           data = train, trials = 10, rules = TRUE)
summary(dt)
pred <- predict(dt, newdata = test)
confusionMatrix(pred,test$magcat)
# acc 0.4909, no inf. 0.2639, kappa 0.3392

# random forest for absolute magnitude for monthly data
set.seed(7)
rf <- train(abscat ~ duration + day + logprice +
              pricecat + season + month, data = train,
            method="rf",
            metric=metric, trControl=control)
pred <- predict(rf, test)
confusionMatrix(pred, test$abscat)
# acc 0.5666, no inf. 0.2639, kappa 0.4398

# decision tree for logcat for daily data # didn't really work
# prediction was always 0
# maybe need for SMOTE by library(DMwR) SMOTE()
library(C50)
dt <- C5.0(logcat ~ duration + day + logprice +
             pricecat + season + month,
           data = train, trials = 10, rules = TRUE)
summary(dt)
pred <- predict(dt, newdata = test)
confusionMatrix(pred,test$logcat)
# acc 0.427, no inf. 0.2516, kappa 0.2614

# decision tree for absolute magcat for weekly data
library(C50)
dt <- C5.0(abscat ~ duration + day + logprice +
             pricecat + season + month,
           data = train, trials = 10, rules = TRUE)
summary(dt)
pred <- predict(dt, newdata = test)
confusionMatrix(pred,test$abscat)
# acc 0.581, no inf. 0.44, kappa 0.3651

# decision tree for magcat for weekly data
library(C50)
dt <- C5.0(magcat ~ duration + day + logprice +
             pricecat + season + month,
           data = train, trials = 10, rules = TRUE)
summary(dt)
pred <- predict(dt, newdata = test)
confusionMatrix(pred,test$magcat)
# acc 0.565, no inf. 0.44, kappa 0.317

# decision tree for change of magnitude for monthly data
# didn't work out
library(C50)
dt <- C5.0(factor(magnitude) ~ duration + day + logprice +
             pricecat + season + month,
           data = train, trials = 10, rules = TRUE)
summary(dt)
pred <- predict(dt, newdata = test)
confusionMatrix(pred,factor(test$magnitude))
# acc 0.427, no inf. 0.2516, kappa 0.2614

#### other sampling methods ####
# SMOTE # did not work
library(DMwR)
smote <- SMOTE(eventfac ~ duration + day + logprice +
                 pricecat + season + month,
               data = as.data.frame(train),
               perc.over = 1000,perc.under=200)

#### H20 ####
library(h2o)
localH2O <- h2o.init()

# data to h2o cluster
h2otrain <- as.h2o(train)
h2otest <- as.h2o(test)

y <- h2otrain[19]
x <- h2otrain[4,9:10,14:17]
y <- make.names(h2otrain[19])

#Random Forest not working
system.time(
  rf <- h2o.randomForest(x, y,
                         training_frame = h2otrain,
                         ntrees = 1000, mtries = 3,
                         max_depth = 4, seed = 7)
)


#### lasso ####
library(dplyr)
library(data.table)
x <- df1 %>% select(duration, fullprice, category)
xfactors <-model.matrix(event ~ category,data=df1)[, -1]
X <- as.matrix(data.frame(df1$duration, df1$fullprice,xfactors))
X<- as.data.frame(X)
y <- df1 %>% select(event)
fwrite(X,"X.csv")
fwrite(y,"y.csv")
rm(xfactors,X,x,y)


#### firth ####
library(logistf)
# make dummy variables
library(dplyr)
weekly <- weekly %>%
  mutate(cat271 =
           case_when(category == "271" ~ 1,
                     category != "271" ~ 0)) %>%
  mutate(Sep =
           case_when(month=="September" ~ 1,
                     month != "September" ~ 0))%>%
  mutate(Mar =
           case_when(month=="March" ~ 1,
                     month != "March" ~ 0))%>%
  mutate(cat991 =
           case_when(category == "991" ~ 1,
                     category != "991" ~ 0)) %>%
  mutate(week2 =
           case_when(weekofm=="2" ~ 1,
                     weekofm != "2" ~ 0))%>%
  mutate(week4 =
           case_when(weekofm=="4" ~ 1,
                     weekofm != "4" ~ 0))%>%
  mutate(Feb =
           case_when(month=="February" ~ 1,
                     month != "Fubruary" ~ 0))%>%
  mutate(May =
           case_when(month=="May" ~ 1,
                     month != "May" ~ 0))%>%
  mutate(Oct =
           case_when(month=="October" ~ 1,
                     month != "October" ~ 0))%>%
  mutate(Dec =
           case_when(month=="December" ~ 1,
                     month != "December" ~ 0))%>%
  mutate(pricecat4 =
           case_when(pricecat=="Q4" ~ 1,
                     pricecat != "Q4" ~ 0))

# by lasso
firth = logistf(event ~ duration + fullprice+Feb+Oct+cat991,
                 data=weekly)
summary(firth)

# by ENet
firthe = logistf(event ~ duration + fullprice+ week2+week4+Feb+Mar+
                   May+Sep+Oct+Dec+cat271+cat991,
                data=weekly)
summary(firthe)

exp(coef(firthe))
